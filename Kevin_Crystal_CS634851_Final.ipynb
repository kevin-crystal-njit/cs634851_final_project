{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f032ba74-7752-43d0-b533-69f7093cccf8",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50500bf5-4955-401c-a334-10adc72fe800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 14:52:00.303631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0fa79-d162-4003-b3a1-de082d3e77bb",
   "metadata": {},
   "source": [
    "\n",
    "# Load the dataset.\n",
    "\n",
    "For this evalution, I am using the IMDB dataset, a collection of 50,000 movie reviews appropriate for training and testing binary sentiment classification models. Because it comes included as part of the sklearn library, it is loaded as an import rather than read from a text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e982f28-0969-46be-a6c1-70ccdd60574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset\n",
    "num_words = 5000 \n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5005a24-e468-409e-82ab-e89918164d15",
   "metadata": {},
   "source": [
    "# Define a function to compute classification metrics\n",
    "\n",
    "The function will take a confusion matrix as its argument and return a dictionary with all of the Module 8 metrics, which will be in a useful form to be aggregated for tabular presentation after all models have been trained and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01c603a5-0864-4504-ad55-5959bff610a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier_metrics(conf_matrix):\n",
    "    tp = conf_matrix[1][1]\n",
    "    tn = conf_matrix[0][0]\n",
    "    fp = conf_matrix[0][1]\n",
    "    fn = conf_matrix[1][0]\n",
    "\n",
    "    p = tp + fn # actual positives\n",
    "    n = tn + fp # actual negatives\n",
    "\n",
    "    # Metrics\n",
    "    tpr = tp / p\n",
    "    fnr = fn / p\n",
    "    tnr = tn / n\n",
    "    fpr = fp / n\n",
    "    precision = tp / (tp + fp)\n",
    "    fdr = fp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    f1_score = 2 * (precision * tpr) / (precision + tpr)\n",
    "    accuracy = (tp + tn) / (p + n)\n",
    "    bacc = (tpr + tnr) / 2\n",
    "    tss = tpr - fpr\n",
    "    hss = 2 * ((tp * tn - fp * fn) / ((p * n) + (tp + fp) * (tn + fn)))\n",
    "\n",
    "    # Dictionary for all of the metrics\n",
    "    metrics_dict = {\n",
    "        'Sensitivity': tpr,\n",
    "        'Specificity': tnr,\n",
    "        'Precision': precision,\n",
    "        'Negative Predictive Value': npv,\n",
    "        'False Positive Rate': fpr,\n",
    "        'False Discovery Rate': fdr,\n",
    "        'False Negative Rate': fnr,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 Score': f1_score,\n",
    "        'Balanced Accuracy': bacc,\n",
    "        'True Skill Statistic': tss,\n",
    "        'Heidke Skill Score': hss\n",
    "    }\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a97b2b-a1b2-4a8f-b69c-6da619d6c0f2",
   "metadata": {},
   "source": [
    "# Train and evaluate the three models\n",
    "\n",
    "Implementation for LSTM used reference to https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df53a19-65f8-4c9b-bcb3-b24ef70c8bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step\n",
      "LSTM completed\n",
      "Fold 2/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step\n",
      "LSTM completed\n",
      "Fold 3/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 131ms/step\n",
      "LSTM completed\n",
      "Fold 4/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 142ms/step\n",
      "LSTM completed\n",
      "Fold 5/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step\n",
      "LSTM completed\n",
      "Fold 6/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step\n",
      "LSTM completed\n",
      "Fold 7/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step\n",
      "LSTM completed\n",
      "Fold 8/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step\n",
      "LSTM completed\n",
      "Fold 9/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step\n",
      "LSTM completed\n",
      "Fold 10/10\n",
      "Random Forest completed\n",
      "K-Nearest Neighbors completed\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step\n",
      "LSTM completed\n"
     ]
    }
   ],
   "source": [
    "# Initialize KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store metrics for each classifier\n",
    "metrics_dict = {\n",
    "    'random_forest': [],\n",
    "    'knn': [],\n",
    "    'lstm': []\n",
    "}\n",
    "\n",
    "# Perform 10-fold cross-validation for each classifier\n",
    "fold = 1\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print(f'Fold {fold}/10')\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    # Random Forest\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    rf_clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_rf = rf_clf.predict(X_val_fold)\n",
    "    conf_matrix_rf = confusion_matrix(y_val_fold, y_pred_rf)\n",
    "    metrics_rf = get_classifier_metrics(conf_matrix_rf)\n",
    "    metrics_dict['random_forest'].append(metrics_rf)\n",
    "    print('Random Forest completed')\n",
    "\n",
    "    # K-Nearest Neighbors\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    knn_clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_knn = knn_clf.predict(X_val_fold)\n",
    "    conf_matrix_knn = confusion_matrix(y_val_fold, y_pred_knn)\n",
    "    metrics_knn = get_classifier_metrics(conf_matrix_knn)\n",
    "    metrics_dict['knn'].append(metrics_knn)\n",
    "    print('K-Nearest Neighbors completed')\n",
    "    \n",
    "    # LSTM - Implementation for this used reference to https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "    lstm_clf = Sequential()\n",
    "    lstm_clf.add(Embedding(num_words, 32))\n",
    "    lstm_clf.add(LSTM(100))\n",
    "    lstm_clf.add(Dense(1, activation='sigmoid'))\n",
    "    lstm_clf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    lstm_clf.fit(X_train_fold, y_train_fold, epochs=2, batch_size=64, verbose=0)\n",
    "    y_pred_lstm = np.round(lstm_clf.predict(X_val_fold)).astype(int)\n",
    "    conf_matrix_lstm = confusion_matrix(y_val_fold, y_pred_lstm)\n",
    "    metrics_lstm = get_classifier_metrics(conf_matrix_lstm)\n",
    "    metrics_dict['lstm'].append(metrics_lstm)\n",
    "    print('LSTM completed')\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f09ca7b-5176-4148-8345-bf504adfcc38",
   "metadata": {},
   "source": [
    "# Define a function to present the metrics data in tabular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "396880fd-5d8b-44d8-bf4e-8ecb0fdae687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_dataframe(metrics_dict, classifier_name):\n",
    "    metrics_df = pd.DataFrame(metrics_dict[classifier_name])\n",
    "    average_metrics = metrics_df.mean().to_frame().T\n",
    "    metrics_df = pd.concat([metrics_df, average_metrics], ignore_index=True)\n",
    "    metrics_df.index = [f'Fold {i+1}' for i in range(metrics_df.shape[0] - 1)] + ['Average']\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858ac517-2be4-4bd8-a066-f6a4eaa81669",
   "metadata": {},
   "source": [
    "# Random Forest Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26f61c05-d6d1-4640-8a6e-f9aa80dec2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Negative Predictive Value</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistic</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.485194</td>\n",
       "      <td>0.596788</td>\n",
       "      <td>0.572581</td>\n",
       "      <td>0.510116</td>\n",
       "      <td>0.403212</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.514806</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.525277</td>\n",
       "      <td>0.540991</td>\n",
       "      <td>0.081981</td>\n",
       "      <td>0.082337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.499197</td>\n",
       "      <td>0.551834</td>\n",
       "      <td>0.525338</td>\n",
       "      <td>0.525836</td>\n",
       "      <td>0.448166</td>\n",
       "      <td>0.474662</td>\n",
       "      <td>0.500803</td>\n",
       "      <td>0.52560</td>\n",
       "      <td>0.511934</td>\n",
       "      <td>0.525516</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.051103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.495153</td>\n",
       "      <td>0.549128</td>\n",
       "      <td>0.518613</td>\n",
       "      <td>0.525797</td>\n",
       "      <td>0.450872</td>\n",
       "      <td>0.481387</td>\n",
       "      <td>0.504847</td>\n",
       "      <td>0.52240</td>\n",
       "      <td>0.506612</td>\n",
       "      <td>0.522141</td>\n",
       "      <td>0.044282</td>\n",
       "      <td>0.044345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.513776</td>\n",
       "      <td>0.567930</td>\n",
       "      <td>0.536833</td>\n",
       "      <td>0.545110</td>\n",
       "      <td>0.432070</td>\n",
       "      <td>0.463167</td>\n",
       "      <td>0.486224</td>\n",
       "      <td>0.54120</td>\n",
       "      <td>0.525052</td>\n",
       "      <td>0.540853</td>\n",
       "      <td>0.081707</td>\n",
       "      <td>0.081825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.501608</td>\n",
       "      <td>0.570860</td>\n",
       "      <td>0.536543</td>\n",
       "      <td>0.536275</td>\n",
       "      <td>0.429140</td>\n",
       "      <td>0.463457</td>\n",
       "      <td>0.498392</td>\n",
       "      <td>0.53640</td>\n",
       "      <td>0.518488</td>\n",
       "      <td>0.536234</td>\n",
       "      <td>0.072468</td>\n",
       "      <td>0.072643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 6</th>\n",
       "      <td>0.503150</td>\n",
       "      <td>0.591057</td>\n",
       "      <td>0.559545</td>\n",
       "      <td>0.535346</td>\n",
       "      <td>0.408943</td>\n",
       "      <td>0.440455</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.54640</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.547103</td>\n",
       "      <td>0.094207</td>\n",
       "      <td>0.094547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 7</th>\n",
       "      <td>0.502811</td>\n",
       "      <td>0.562550</td>\n",
       "      <td>0.532766</td>\n",
       "      <td>0.532830</td>\n",
       "      <td>0.437450</td>\n",
       "      <td>0.467234</td>\n",
       "      <td>0.497189</td>\n",
       "      <td>0.53280</td>\n",
       "      <td>0.517355</td>\n",
       "      <td>0.532681</td>\n",
       "      <td>0.065361</td>\n",
       "      <td>0.065478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 8</th>\n",
       "      <td>0.473473</td>\n",
       "      <td>0.589968</td>\n",
       "      <td>0.533514</td>\n",
       "      <td>0.530802</td>\n",
       "      <td>0.410032</td>\n",
       "      <td>0.466486</td>\n",
       "      <td>0.526527</td>\n",
       "      <td>0.53200</td>\n",
       "      <td>0.501704</td>\n",
       "      <td>0.531720</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.063876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 9</th>\n",
       "      <td>0.497517</td>\n",
       "      <td>0.575077</td>\n",
       "      <td>0.522609</td>\n",
       "      <td>0.550370</td>\n",
       "      <td>0.424923</td>\n",
       "      <td>0.477391</td>\n",
       "      <td>0.502483</td>\n",
       "      <td>0.53760</td>\n",
       "      <td>0.509754</td>\n",
       "      <td>0.536297</td>\n",
       "      <td>0.072594</td>\n",
       "      <td>0.072786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 10</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.562600</td>\n",
       "      <td>0.547718</td>\n",
       "      <td>0.541313</td>\n",
       "      <td>0.437400</td>\n",
       "      <td>0.452282</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.54440</td>\n",
       "      <td>0.536804</td>\n",
       "      <td>0.544458</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.499819</td>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.538606</td>\n",
       "      <td>0.533379</td>\n",
       "      <td>0.428221</td>\n",
       "      <td>0.461394</td>\n",
       "      <td>0.500181</td>\n",
       "      <td>0.53568</td>\n",
       "      <td>0.518283</td>\n",
       "      <td>0.535799</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.071791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sensitivity  Specificity  Precision  Negative Predictive Value  \\\n",
       "Fold 1      0.485194     0.596788   0.572581                   0.510116   \n",
       "Fold 2      0.499197     0.551834   0.525338                   0.525836   \n",
       "Fold 3      0.495153     0.549128   0.518613                   0.525797   \n",
       "Fold 4      0.513776     0.567930   0.536833                   0.545110   \n",
       "Fold 5      0.501608     0.570860   0.536543                   0.536275   \n",
       "Fold 6      0.503150     0.591057   0.559545                   0.535346   \n",
       "Fold 7      0.502811     0.562550   0.532766                   0.532830   \n",
       "Fold 8      0.473473     0.589968   0.533514                   0.530802   \n",
       "Fold 9      0.497517     0.575077   0.522609                   0.550370   \n",
       "Fold 10     0.526316     0.562600   0.547718                   0.541313   \n",
       "Average     0.499819     0.571779   0.538606                   0.533379   \n",
       "\n",
       "         False Positive Rate  False Discovery Rate  False Negative Rate  \\\n",
       "Fold 1              0.403212              0.427419             0.514806   \n",
       "Fold 2              0.448166              0.474662             0.500803   \n",
       "Fold 3              0.450872              0.481387             0.504847   \n",
       "Fold 4              0.432070              0.463167             0.486224   \n",
       "Fold 5              0.429140              0.463457             0.498392   \n",
       "Fold 6              0.408943              0.440455             0.496850   \n",
       "Fold 7              0.437450              0.467234             0.497189   \n",
       "Fold 8              0.410032              0.466486             0.526527   \n",
       "Fold 9              0.424923              0.477391             0.502483   \n",
       "Fold 10             0.437400              0.452282             0.473684   \n",
       "Average             0.428221              0.461394             0.500181   \n",
       "\n",
       "         Accuracy  F1 Score  Balanced Accuracy  True Skill Statistic  \\\n",
       "Fold 1    0.53800  0.525277           0.540991              0.081981   \n",
       "Fold 2    0.52560  0.511934           0.525516              0.051032   \n",
       "Fold 3    0.52240  0.506612           0.522141              0.044282   \n",
       "Fold 4    0.54120  0.525052           0.540853              0.081707   \n",
       "Fold 5    0.53640  0.518488           0.536234              0.072468   \n",
       "Fold 6    0.54640  0.529851           0.547103              0.094207   \n",
       "Fold 7    0.53280  0.517355           0.532681              0.065361   \n",
       "Fold 8    0.53200  0.501704           0.531720              0.063441   \n",
       "Fold 9    0.53760  0.509754           0.536297              0.072594   \n",
       "Fold 10   0.54440  0.536804           0.544458              0.088916   \n",
       "Average   0.53568  0.518283           0.535799              0.071599   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "Fold 1             0.082337  \n",
       "Fold 2             0.051103  \n",
       "Fold 3             0.044345  \n",
       "Fold 4             0.081825  \n",
       "Fold 5             0.072643  \n",
       "Fold 6             0.094547  \n",
       "Fold 7             0.065478  \n",
       "Fold 8             0.063876  \n",
       "Fold 9             0.072786  \n",
       "Fold 10            0.088973  \n",
       "Average            0.071791  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_rf = create_metrics_dataframe(metrics_dict, 'random_forest')\n",
    "metrics_df_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2507df2d-1b68-4654-a3e8-790aac93327d",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd7ded4-0fb3-45aa-aba6-ea2521195e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Negative Predictive Value</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistic</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.428246</td>\n",
       "      <td>0.575655</td>\n",
       "      <td>0.529081</td>\n",
       "      <td>0.474895</td>\n",
       "      <td>0.424345</td>\n",
       "      <td>0.470919</td>\n",
       "      <td>0.571754</td>\n",
       "      <td>0.49800</td>\n",
       "      <td>0.473353</td>\n",
       "      <td>0.501951</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>0.003938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.432584</td>\n",
       "      <td>0.571770</td>\n",
       "      <td>0.500929</td>\n",
       "      <td>0.503511</td>\n",
       "      <td>0.428230</td>\n",
       "      <td>0.499071</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.50240</td>\n",
       "      <td>0.464255</td>\n",
       "      <td>0.502177</td>\n",
       "      <td>0.004355</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.428110</td>\n",
       "      <td>0.570523</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.429477</td>\n",
       "      <td>0.505597</td>\n",
       "      <td>0.571890</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.458874</td>\n",
       "      <td>0.499316</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>-0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.448947</td>\n",
       "      <td>0.568720</td>\n",
       "      <td>0.503636</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.431280</td>\n",
       "      <td>0.496364</td>\n",
       "      <td>0.551053</td>\n",
       "      <td>0.50960</td>\n",
       "      <td>0.474722</td>\n",
       "      <td>0.508833</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.017794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.436495</td>\n",
       "      <td>0.596338</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>0.516552</td>\n",
       "      <td>0.403662</td>\n",
       "      <td>0.482857</td>\n",
       "      <td>0.563505</td>\n",
       "      <td>0.51680</td>\n",
       "      <td>0.473409</td>\n",
       "      <td>0.516416</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.033258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 6</th>\n",
       "      <td>0.439370</td>\n",
       "      <td>0.546341</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.453659</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560630</td>\n",
       "      <td>0.49200</td>\n",
       "      <td>0.467728</td>\n",
       "      <td>0.492856</td>\n",
       "      <td>-0.014288</td>\n",
       "      <td>-0.014369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 7</th>\n",
       "      <td>0.460241</td>\n",
       "      <td>0.548207</td>\n",
       "      <td>0.502632</td>\n",
       "      <td>0.505882</td>\n",
       "      <td>0.451793</td>\n",
       "      <td>0.497368</td>\n",
       "      <td>0.539759</td>\n",
       "      <td>0.50440</td>\n",
       "      <td>0.480503</td>\n",
       "      <td>0.504224</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.008481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 8</th>\n",
       "      <td>0.431672</td>\n",
       "      <td>0.574841</td>\n",
       "      <td>0.501401</td>\n",
       "      <td>0.505248</td>\n",
       "      <td>0.425159</td>\n",
       "      <td>0.498599</td>\n",
       "      <td>0.568328</td>\n",
       "      <td>0.50360</td>\n",
       "      <td>0.463931</td>\n",
       "      <td>0.503256</td>\n",
       "      <td>0.006513</td>\n",
       "      <td>0.006580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 9</th>\n",
       "      <td>0.447020</td>\n",
       "      <td>0.540248</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.510981</td>\n",
       "      <td>0.459752</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.552980</td>\n",
       "      <td>0.49520</td>\n",
       "      <td>0.461144</td>\n",
       "      <td>0.493634</td>\n",
       "      <td>-0.012732</td>\n",
       "      <td>-0.012780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 10</th>\n",
       "      <td>0.452951</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.503546</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.449438</td>\n",
       "      <td>0.496454</td>\n",
       "      <td>0.547049</td>\n",
       "      <td>0.50160</td>\n",
       "      <td>0.476910</td>\n",
       "      <td>0.501756</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.003529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.440564</td>\n",
       "      <td>0.564321</td>\n",
       "      <td>0.502896</td>\n",
       "      <td>0.502111</td>\n",
       "      <td>0.435679</td>\n",
       "      <td>0.497104</td>\n",
       "      <td>0.559436</td>\n",
       "      <td>0.50236</td>\n",
       "      <td>0.469483</td>\n",
       "      <td>0.502442</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sensitivity  Specificity  Precision  Negative Predictive Value  \\\n",
       "Fold 1      0.428246     0.575655   0.529081                   0.474895   \n",
       "Fold 2      0.432584     0.571770   0.500929                   0.503511   \n",
       "Fold 3      0.428110     0.570523   0.494403                   0.504202   \n",
       "Fold 4      0.448947     0.568720   0.503636                   0.514286   \n",
       "Fold 5      0.436495     0.596338   0.517143                   0.516552   \n",
       "Fold 6      0.439370     0.546341   0.500000                   0.485549   \n",
       "Fold 7      0.460241     0.548207   0.502632                   0.505882   \n",
       "Fold 8      0.431672     0.574841   0.501401                   0.505248   \n",
       "Fold 9      0.447020     0.540248   0.476190                   0.510981   \n",
       "Fold 10     0.452951     0.550562   0.503546                   0.500000   \n",
       "Average     0.440564     0.564321   0.502896                   0.502111   \n",
       "\n",
       "         False Positive Rate  False Discovery Rate  False Negative Rate  \\\n",
       "Fold 1              0.424345              0.470919             0.571754   \n",
       "Fold 2              0.428230              0.499071             0.567416   \n",
       "Fold 3              0.429477              0.505597             0.571890   \n",
       "Fold 4              0.431280              0.496364             0.551053   \n",
       "Fold 5              0.403662              0.482857             0.563505   \n",
       "Fold 6              0.453659              0.500000             0.560630   \n",
       "Fold 7              0.451793              0.497368             0.539759   \n",
       "Fold 8              0.425159              0.498599             0.568328   \n",
       "Fold 9              0.459752              0.523810             0.552980   \n",
       "Fold 10             0.449438              0.496454             0.547049   \n",
       "Average             0.435679              0.497104             0.559436   \n",
       "\n",
       "         Accuracy  F1 Score  Balanced Accuracy  True Skill Statistic  \\\n",
       "Fold 1    0.49800  0.473353           0.501951              0.003901   \n",
       "Fold 2    0.50240  0.464255           0.502177              0.004355   \n",
       "Fold 3    0.50000  0.458874           0.499316             -0.001367   \n",
       "Fold 4    0.50960  0.474722           0.508833              0.017667   \n",
       "Fold 5    0.51680  0.473409           0.516416              0.032833   \n",
       "Fold 6    0.49200  0.467728           0.492856             -0.014288   \n",
       "Fold 7    0.50440  0.480503           0.504224              0.008448   \n",
       "Fold 8    0.50360  0.463931           0.503256              0.006513   \n",
       "Fold 9    0.49520  0.461144           0.493634             -0.012732   \n",
       "Fold 10   0.50160  0.476910           0.501756              0.003512   \n",
       "Average   0.50236  0.469483           0.502442              0.004884   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "Fold 1             0.003938  \n",
       "Fold 2             0.004397  \n",
       "Fold 3            -0.001381  \n",
       "Fold 4             0.017794  \n",
       "Fold 5             0.033258  \n",
       "Fold 6            -0.014369  \n",
       "Fold 7             0.008481  \n",
       "Fold 8             0.006580  \n",
       "Fold 9            -0.012780  \n",
       "Fold 10            0.003529  \n",
       "Average            0.004945  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_knn = create_metrics_dataframe(metrics_dict, 'knn')\n",
    "metrics_df_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75b9a0-79e7-4bb9-a484-716762bf1863",
   "metadata": {},
   "source": [
    "# LSTM Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d714119-f708-4bd1-aed0-5fcb81e0bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Negative Predictive Value</th>\n",
       "      <th>False Positive Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistic</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.889901</td>\n",
       "      <td>0.848690</td>\n",
       "      <td>0.867506</td>\n",
       "      <td>0.873803</td>\n",
       "      <td>0.151310</td>\n",
       "      <td>0.132494</td>\n",
       "      <td>0.110099</td>\n",
       "      <td>0.87040</td>\n",
       "      <td>0.878561</td>\n",
       "      <td>0.869296</td>\n",
       "      <td>0.738591</td>\n",
       "      <td>0.739947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.479936</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>0.753149</td>\n",
       "      <td>0.620164</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.246851</td>\n",
       "      <td>0.520064</td>\n",
       "      <td>0.66240</td>\n",
       "      <td>0.586275</td>\n",
       "      <td>0.661818</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>0.346704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.851373</td>\n",
       "      <td>0.829635</td>\n",
       "      <td>0.830575</td>\n",
       "      <td>0.850528</td>\n",
       "      <td>0.170365</td>\n",
       "      <td>0.169425</td>\n",
       "      <td>0.148627</td>\n",
       "      <td>0.84040</td>\n",
       "      <td>0.840846</td>\n",
       "      <td>0.840504</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.681056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.809637</td>\n",
       "      <td>0.825489</td>\n",
       "      <td>0.915996</td>\n",
       "      <td>0.190363</td>\n",
       "      <td>0.174511</td>\n",
       "      <td>0.076175</td>\n",
       "      <td>0.86600</td>\n",
       "      <td>0.871893</td>\n",
       "      <td>0.866731</td>\n",
       "      <td>0.733462</td>\n",
       "      <td>0.737452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.552251</td>\n",
       "      <td>0.846338</td>\n",
       "      <td>0.780682</td>\n",
       "      <td>0.656173</td>\n",
       "      <td>0.153662</td>\n",
       "      <td>0.219318</td>\n",
       "      <td>0.447749</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>0.646893</td>\n",
       "      <td>0.699294</td>\n",
       "      <td>0.398588</td>\n",
       "      <td>0.416845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 6</th>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.857883</td>\n",
       "      <td>0.903394</td>\n",
       "      <td>0.156098</td>\n",
       "      <td>0.142117</td>\n",
       "      <td>0.087402</td>\n",
       "      <td>0.87880</td>\n",
       "      <td>0.884395</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>0.756501</td>\n",
       "      <td>0.758882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 7</th>\n",
       "      <td>0.781526</td>\n",
       "      <td>0.943426</td>\n",
       "      <td>0.931992</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.056574</td>\n",
       "      <td>0.068008</td>\n",
       "      <td>0.218474</td>\n",
       "      <td>0.86280</td>\n",
       "      <td>0.850153</td>\n",
       "      <td>0.862476</td>\n",
       "      <td>0.724952</td>\n",
       "      <td>0.734927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 8</th>\n",
       "      <td>0.795820</td>\n",
       "      <td>0.869427</td>\n",
       "      <td>0.857886</td>\n",
       "      <td>0.811293</td>\n",
       "      <td>0.130573</td>\n",
       "      <td>0.142114</td>\n",
       "      <td>0.204180</td>\n",
       "      <td>0.83280</td>\n",
       "      <td>0.825688</td>\n",
       "      <td>0.832623</td>\n",
       "      <td>0.665247</td>\n",
       "      <td>0.667207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 9</th>\n",
       "      <td>0.480960</td>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.732661</td>\n",
       "      <td>0.632689</td>\n",
       "      <td>0.164087</td>\n",
       "      <td>0.267339</td>\n",
       "      <td>0.519040</td>\n",
       "      <td>0.66440</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.658437</td>\n",
       "      <td>0.316874</td>\n",
       "      <td>0.339389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 10</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.853130</td>\n",
       "      <td>0.856132</td>\n",
       "      <td>0.865635</td>\n",
       "      <td>0.146870</td>\n",
       "      <td>0.143868</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.86080</td>\n",
       "      <td>0.862233</td>\n",
       "      <td>0.860776</td>\n",
       "      <td>0.721551</td>\n",
       "      <td>0.721659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.753661</td>\n",
       "      <td>0.852380</td>\n",
       "      <td>0.829395</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.147620</td>\n",
       "      <td>0.170605</td>\n",
       "      <td>0.246339</td>\n",
       "      <td>0.80388</td>\n",
       "      <td>0.782765</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>0.614407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sensitivity  Specificity  Precision  Negative Predictive Value  \\\n",
       "Fold 1      0.889901     0.848690   0.867506                   0.873803   \n",
       "Fold 2      0.479936     0.843700   0.753149                   0.620164   \n",
       "Fold 3      0.851373     0.829635   0.830575                   0.850528   \n",
       "Fold 4      0.923825     0.809637   0.825489                   0.915996   \n",
       "Fold 5      0.552251     0.846338   0.780682                   0.656173   \n",
       "Fold 6      0.912598     0.843902   0.857883                   0.903394   \n",
       "Fold 7      0.781526     0.943426   0.931992                   0.813187   \n",
       "Fold 8      0.795820     0.869427   0.857886                   0.811293   \n",
       "Fold 9      0.480960     0.835913   0.732661                   0.632689   \n",
       "Fold 10     0.868421     0.853130   0.856132                   0.865635   \n",
       "Average     0.753661     0.852380   0.829395                   0.794286   \n",
       "\n",
       "         False Positive Rate  False Discovery Rate  False Negative Rate  \\\n",
       "Fold 1              0.151310              0.132494             0.110099   \n",
       "Fold 2              0.156300              0.246851             0.520064   \n",
       "Fold 3              0.170365              0.169425             0.148627   \n",
       "Fold 4              0.190363              0.174511             0.076175   \n",
       "Fold 5              0.153662              0.219318             0.447749   \n",
       "Fold 6              0.156098              0.142117             0.087402   \n",
       "Fold 7              0.056574              0.068008             0.218474   \n",
       "Fold 8              0.130573              0.142114             0.204180   \n",
       "Fold 9              0.164087              0.267339             0.519040   \n",
       "Fold 10             0.146870              0.143868             0.131579   \n",
       "Average             0.147620              0.170605             0.246339   \n",
       "\n",
       "         Accuracy  F1 Score  Balanced Accuracy  True Skill Statistic  \\\n",
       "Fold 1    0.87040  0.878561           0.869296              0.738591   \n",
       "Fold 2    0.66240  0.586275           0.661818              0.323636   \n",
       "Fold 3    0.84040  0.840846           0.840504              0.681009   \n",
       "Fold 4    0.86600  0.871893           0.866731              0.733462   \n",
       "Fold 5    0.70000  0.646893           0.699294              0.398588   \n",
       "Fold 6    0.87880  0.884395           0.878250              0.756501   \n",
       "Fold 7    0.86280  0.850153           0.862476              0.724952   \n",
       "Fold 8    0.83280  0.825688           0.832623              0.665247   \n",
       "Fold 9    0.66440  0.580710           0.658437              0.316874   \n",
       "Fold 10   0.86080  0.862233           0.860776              0.721551   \n",
       "Average   0.80388  0.782765           0.803021              0.606041   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "Fold 1             0.739947  \n",
       "Fold 2             0.346704  \n",
       "Fold 3             0.681056  \n",
       "Fold 4             0.737452  \n",
       "Fold 5             0.416845  \n",
       "Fold 6             0.758882  \n",
       "Fold 7             0.734927  \n",
       "Fold 8             0.667207  \n",
       "Fold 9             0.339389  \n",
       "Fold 10            0.721659  \n",
       "Average            0.614407  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_gru = create_metrics_dataframe(metrics_dict, 'lstm')\n",
    "metrics_df_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6cdd6f-03ec-443c-88e1-e06462fc35f3",
   "metadata": {},
   "source": [
    "# Show the comparison of the averages for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1e1c9e1-65e3-4e33-b283-62d3cf7c58b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.499819</td>\n",
       "      <td>0.440564</td>\n",
       "      <td>0.753661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.571779</td>\n",
       "      <td>0.564321</td>\n",
       "      <td>0.852380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.538606</td>\n",
       "      <td>0.502896</td>\n",
       "      <td>0.829395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Predictive Value</th>\n",
       "      <td>0.533379</td>\n",
       "      <td>0.502111</td>\n",
       "      <td>0.794286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate</th>\n",
       "      <td>0.428221</td>\n",
       "      <td>0.435679</td>\n",
       "      <td>0.147620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <td>0.461394</td>\n",
       "      <td>0.497104</td>\n",
       "      <td>0.170605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative Rate</th>\n",
       "      <td>0.500181</td>\n",
       "      <td>0.559436</td>\n",
       "      <td>0.246339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.535680</td>\n",
       "      <td>0.502360</td>\n",
       "      <td>0.803880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.518283</td>\n",
       "      <td>0.469483</td>\n",
       "      <td>0.782765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.535799</td>\n",
       "      <td>0.502442</td>\n",
       "      <td>0.803021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Skill Statistic</th>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.606041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heidke Skill Score</th>\n",
       "      <td>0.071791</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.614407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Random Forest       KNN      LSTM\n",
       "Sensitivity                     0.499819  0.440564  0.753661\n",
       "Specificity                     0.571779  0.564321  0.852380\n",
       "Precision                       0.538606  0.502896  0.829395\n",
       "Negative Predictive Value       0.533379  0.502111  0.794286\n",
       "False Positive Rate             0.428221  0.435679  0.147620\n",
       "False Discovery Rate            0.461394  0.497104  0.170605\n",
       "False Negative Rate             0.500181  0.559436  0.246339\n",
       "Accuracy                        0.535680  0.502360  0.803880\n",
       "F1 Score                        0.518283  0.469483  0.782765\n",
       "Balanced Accuracy               0.535799  0.502442  0.803021\n",
       "True Skill Statistic            0.071599  0.004884  0.606041\n",
       "Heidke Skill Score              0.071791  0.004945  0.614407"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_data = {'Random Forest': metrics_df_rf.loc['Average']\n",
    "               ,'KNN': metrics_df_knn.loc['Average']\n",
    "               ,'LSTM': metrics_df_gru.loc['Average']\n",
    "               }\n",
    "average_metrics_df = pd.DataFrame(average_data)\n",
    "average_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4caa5b0-ce52-4046-9e30-c1e061ad1016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
